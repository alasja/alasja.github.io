---
title: "5.4 传感器"
sidebar: rtr
layout: book
permalink: rtr_ch5_sensor.html
---

### 5.4 传感器
光线在场景中传递，其中一部分会被图像传感器捕捉到。一个图像传感器实际上有很多更小的传感器组成：眼睛中的视锥细胞，数码相机中的二极管，或者胶卷中的染色颗粒。这些传感器探测他们表面的辐照度，并发出一个颜色信号。传感器本身并不能产生图像，他们平摊了照射的光线。因此，一个完整的成像系统包括一个有光圈的光线遮罩好让光线能够进入到传感器上。镜头的作用就是让进入传感器的光线都是一个特定的方向。可见图5.10 。

![图](/images/RTR3.05.10.png)
图5.10

遮罩、光圈、镜头共同定义了传感线接受光线的特定方向；他们把进入的光线平均分布到一个小区域上。这些传感器不是测算平均辐照度（每个表面上的各个方向上光线的密度），而是测算平均`辐射率(radiance)`。`辐射率`是每个方向上光线在每个区域上的密度。`辐射率`（使用符号*L*）可以认为是单条光线的亮度和颜色。类似辐照度，`辐射率`也表示成RGB向量，但取值范围不限。渲染系统也会测算`辐射率`，一般在真是渲染系统中。不过，他们使用的使用简化的概念上的图像传感器模型，可见图5.11

![图](/images/RTR3.05.11.png)
图5.11

这个模型下，每个传感器测量一个单独的辐射率样本，而不是平均值。每个传感器的辐射率样本就是穿过传感器和公共点P的光线，点P也是透视变换投影的中心点，这在4.6.2中已经讲过。在渲染系统中，检测辐射率的传感器被着色器公式计算代替。每次求值的目标就是计算出特定射线上的辐射率。射线的方向在着色公式中表示为`观察向量(view vector)`v（见图5.12）。本书中提到的这个向量v的长度总是假设为1（也就是规范化过的）。

![图](/images/RTR3.05.12.png)
图5.12

传感器上辐射率的值和它产生的信号之间的关系非常的复杂，一般也不是线性的。它受多个因子影响，还可能随着时间和空间位置变换而变换。另外，传感器检测到的值经常会比现实设备支持的范围要大（特别是渲染中的虚拟传感器，它的范围没有限制）。所以辐射率需要被映射到一个合适的范围来表现，一般采用模拟胶卷或者人眼这类物理传感线的行为的方法。相关技术会在5.8、10.11、10.12节讨论。

图5.10中展示的物理图像传感器，与图5.11中展示的概念模型之间有非常重要的区别。物理传感器测量他们区域上辐射率的平均值，镜头固定了入射光线的角度和时间；着色器则单独计算每一条射线上的光照度。这些区别引起的问题，以及解决方法，会在章节5.6，10.13，10.14讨论。



